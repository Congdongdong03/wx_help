#!/usr/bin/env python3
"""
Colesä¸“ç”¨çˆ¬è™« - ä¿®å¤è·¯å¾„ç‰ˆæœ¬
"""

import os
import requests
import time
import logging
from datetime import datetime, date
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from pdf2image import convert_from_bytes
import mysql.connector
from config import DB_CONFIG

class ColesScraper:
    def __init__(self):
        self.setup_logging()
        self.driver = None
        self.images_dir = None
        self.ensure_directories()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('coles_scraper.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨ - ä¿®å¤è·¯å¾„"""
        import os
        
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        logging.info(f"å½“å‰è„šæœ¬ç›®å½•: {current_dir}")
        
        # æ–¹æ³•1ï¼šå¦‚æœçˆ¬è™«åœ¨ server/src/ ç›®å½•ä¸‹
        if 'server' in current_dir and 'src' in current_dir:
            # ç›´æ¥åœ¨å½“å‰ç›®å½•åˆ›å»º public æ–‡ä»¶å¤¹
            self.images_dir = os.path.join(current_dir, 'public', 'catalogue_images', 'coles')
        else:
            # æ–¹æ³•2ï¼šæ‰‹åŠ¨æŒ‡å®šåˆ°æ­£ç¡®çš„è·¯å¾„
            # æ ¹æ®ä½ çš„APIè·¯å¾„ï¼Œåº”è¯¥æ˜¯ server/src/public/catalogue_images/coles/
            server_src_dir = "/Users/wesley/Desktop/å¸®å¸®/wx_help/server/src"
            if os.path.exists(server_src_dir):
                self.images_dir = os.path.join(server_src_dir, 'public', 'catalogue_images', 'coles')
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±åœ¨å½“å‰ç›®å½•çš„ä¸Šçº§åˆ›å»º
                project_root = os.path.dirname(current_dir)
                self.images_dir = os.path.join(project_root, 'server', 'src', 'public', 'catalogue_images', 'coles')
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.images_dir, exist_ok=True)
        
        logging.info("=" * 60)
        logging.info(f"âœ… Coleså›¾ç‰‡å­˜å‚¨ç›®å½•: {self.images_dir}")
        logging.info(f"âœ… ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(self.images_dir)}")
        logging.info("=" * 60)
    
    def setup_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.implicitly_wait(10)
            
            logging.info("âœ… Chromeæµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def close_driver(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            logging.info("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
    
    def clean_old_files(self):
        """æ¸…ç†æ—§å›¾ç‰‡æ–‡ä»¶"""
        try:
            if os.path.exists(self.images_dir):
                files = [f for f in os.listdir(self.images_dir) if f.endswith(('.jpg', '.jpeg'))]
                for file in files:
                    file_path = os.path.join(self.images_dir, file)
                    os.remove(file_path)
                    logging.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ–‡ä»¶: {file}")
                logging.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {len(files)} ä¸ªæ–‡ä»¶")
            return True
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†æ—§æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def get_coles_pdf_url(self):
        """è·å–Coles PDFé“¾æ¥"""
        try:
            logging.info("ğŸŒ è®¿é—®Colesç›®å½•é¡µé¢...")
            self.driver.get("https://www.coles.com.au/catalogues")
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # å¤šç§æ–¹æ³•æŸ¥æ‰¾PDFé“¾æ¥
            methods = [
                ("æŸ¥æ‰¾'This week's catalogue'", self._find_this_week_catalogue),
                ("æŸ¥æ‰¾Download PDFæŒ‰é’®", self._find_download_pdf_buttons),
                ("æŸ¥æ‰¾æ‰€æœ‰PDFé“¾æ¥", self._find_all_pdf_links)
            ]
            
            for method_name, method_func in methods:
                try:
                    logging.info(f"ğŸ” {method_name}...")
                    pdf_url = method_func()
                    if pdf_url:
                        logging.info(f"âœ… {method_name}æˆåŠŸ: {pdf_url}")
                        return pdf_url
                except Exception as e:
                    logging.warning(f"âš ï¸ {method_name}å¤±è´¥: {e}")
                    continue
            
            logging.error("âŒ æœªæ‰¾åˆ°PDFé“¾æ¥")
            return None
            
        except Exception as e:
            logging.error(f"âŒ è·å–PDFé“¾æ¥å¤±è´¥: {e}")
            return None
    
    def _find_this_week_catalogue(self):
        """æ–¹æ³•1ï¼šæŸ¥æ‰¾'This week's catalogue'"""
        this_week_elements = self.driver.find_elements(By.XPATH, "//*[contains(text(), \"This week's catalogue\")]")
        
        for element in this_week_elements:
            parent = element
            for level in range(10):
                try:
                    download_buttons = parent.find_elements(By.XPATH, ".//*[contains(text(), 'Download PDF') or contains(text(), 'download pdf') or contains(text(), 'PDF')]")
                    
                    for button in download_buttons:
                        href = button.get_attribute('href')
                        if not href:
                            button_parent = button.find_element(By.XPATH, "..")
                            href = button_parent.get_attribute('href')
                        
                        if href and '.pdf' in href.lower():
                            return href
                    
                    parent = parent.find_element(By.XPATH, "..")
                except:
                    break
        return None
    
    def _find_download_pdf_buttons(self):
        """æ–¹æ³•2ï¼šæŸ¥æ‰¾Download PDFæŒ‰é’®"""
        selectors = [
            "//*[contains(text(), 'Download PDF')]",
            "//*[contains(text(), 'download pdf')]", 
            "//*[contains(text(), 'PDF')]",
            "a[href*='.pdf']",
            "button[href*='.pdf']"
        ]
        
        for selector in selectors:
            try:
                if selector.startswith("//"):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                for element in elements:
                    href = element.get_attribute('href')
                    if href and '.pdf' in href.lower():
                        return href
            except:
                continue
        return None
    
    def _find_all_pdf_links(self):
        """æ–¹æ³•3ï¼šæŸ¥æ‰¾æ‰€æœ‰PDFé“¾æ¥"""
        all_links = self.driver.find_elements(By.TAG_NAME, "a")
        for link in all_links:
            href = link.get_attribute('href')
            if href and '.pdf' in href.lower():
                return href
        return None
    
    def download_pdf(self, pdf_url):
        """ä¸‹è½½PDFæ–‡ä»¶"""
        try:
            logging.info("ğŸ“¥ ä¸‹è½½Coles PDF...")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            response = requests.get(pdf_url, headers=headers, timeout=60)
            if response.status_code == 200:
                size_mb = len(response.content) / (1024 * 1024)
                logging.info(f"âœ… PDFä¸‹è½½æˆåŠŸï¼Œå¤§å°: {size_mb:.2f} MB")
                return response.content
            else:
                logging.error(f"âŒ PDFä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"âŒ PDFä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def pdf_to_images(self, pdf_data):
        """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡"""
        try:
            logging.info("ğŸ”„ è½¬æ¢PDFä¸ºå›¾ç‰‡...")
            
            images = convert_from_bytes(
                pdf_data,
                dpi=150,  # å›¾ç‰‡è´¨é‡
                fmt='JPEG'
            )
            
            logging.info(f"âœ… PDFè½¬æ¢æˆåŠŸï¼Œå…± {len(images)} é¡µ")
            return images
            
        except Exception as e:
            logging.error(f"âŒ PDFè½¬æ¢å¤±è´¥: {e}")
            return []
    
    def save_images(self, images):
        """ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°å¹¶è¿”å›è·¯å¾„"""
        try:
            today = date.today()
            date_str = today.strftime('%Y%m%d')
            saved_paths = []
            
            logging.info(f"ğŸ’¾ å¼€å§‹ä¿å­˜ {len(images)} å¼ å›¾ç‰‡åˆ°: {self.images_dir}")
            
            for i, image in enumerate(images, 1):
                filename = f"{date_str}_page{i}.jpg"
                file_path = os.path.join(self.images_dir, filename)
                
                # ä¿å­˜å›¾ç‰‡
                image.save(file_path, 'JPEG', quality=85)
                
                # æ•°æ®åº“è·¯å¾„ï¼ˆAPIä½¿ç”¨ï¼‰
                db_path = f"/catalogue_images/coles/{filename}"
                saved_paths.append((i, db_path))
                
                logging.info(f"ğŸ“„ ç¬¬{i}é¡µ: {filename} ({os.path.getsize(file_path)} bytes)")
            
            logging.info(f"âœ… æ‰€æœ‰å›¾ç‰‡ä¿å­˜å®Œæˆ")
            return saved_paths
            
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜å›¾ç‰‡å¤±è´¥: {e}")
            return []
    
    def save_to_database(self, image_paths):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            logging.info("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
            connection = mysql.connector.connect(**DB_CONFIG)
            cursor = connection.cursor()
            
            # æ¸…é™¤æ—§çš„Colesæ•°æ®
            cursor.execute("DELETE FROM catalogue_images WHERE store_name = 'coles'")
            deleted_count = cursor.rowcount
            logging.info(f"ğŸ—‘ï¸ åˆ é™¤äº† {deleted_count} æ¡æ—§çš„Colesè®°å½•")
            
            # æ’å…¥æ–°æ•°æ®
            today = date.today()
            success_count = 0
            for page_number, file_path in image_paths:
                query = """
                INSERT INTO catalogue_images (store_name, page_number, image_data, week_date)
                VALUES (%s, %s, %s, %s)
                """
                cursor.execute(query, ('coles', page_number, file_path, today))
                success_count += 1
            
            connection.commit()
            cursor.close()
            connection.close()
            
            logging.info(f"âœ… æˆåŠŸä¿å­˜ {success_count} æ¡Colesè®°å½•åˆ°æ•°æ®åº“")
            return True
            
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def run_scraper(self):
        """è¿è¡ŒColesçˆ¬è™«ä¸»æµç¨‹"""
        try:
            logging.info("ğŸš€" + "=" * 50)
            logging.info("ğŸ›’ Colesè‡ªåŠ¨åŒ–çˆ¬è™«å¼€å§‹è¿è¡Œ")
            logging.info(f"â° è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logging.info("ğŸš€" + "=" * 50)
            
            # æ­¥éª¤1ï¼šæ¸…ç†æ—§æ–‡ä»¶
            self.clean_old_files()
            
            # æ­¥éª¤2ï¼šå¯åŠ¨æµè§ˆå™¨
            if not self.setup_driver():
                logging.error("âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥")
                return False
            
            # æ­¥éª¤3ï¼šè·å–PDF URL
            pdf_url = self.get_coles_pdf_url()
            if not pdf_url:
                logging.error("âŒ æœªæ‰¾åˆ°PDFé“¾æ¥")
                return False
            
            # æ­¥éª¤4ï¼šä¸‹è½½PDF
            pdf_data = self.download_pdf(pdf_url)
            if not pdf_data:
                logging.error("âŒ PDFä¸‹è½½å¤±è´¥")
                return False
            
            # æ­¥éª¤5ï¼šè½¬æ¢ä¸ºå›¾ç‰‡
            images = self.pdf_to_images(pdf_data)
            if not images:
                logging.error("âŒ PDFè½¬æ¢å¤±è´¥")
                return False
            
            # æ­¥éª¤6ï¼šä¿å­˜å›¾ç‰‡
            image_paths = self.save_images(images)
            if not image_paths:
                logging.error("âŒ å›¾ç‰‡ä¿å­˜å¤±è´¥")
                return False
            
            # æ­¥éª¤7ï¼šä¿å­˜åˆ°æ•°æ®åº“
            if not self.save_to_database(image_paths):
                logging.error("âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥")
                return False
            
            # æˆåŠŸå®Œæˆ
            logging.info("ğŸ‰" + "=" * 50)
            logging.info("ğŸ‰ Colesçˆ¬è™«æ‰§è¡ŒæˆåŠŸï¼")
            logging.info(f"ğŸ“Š å…±å¤„ç† {len(image_paths)} å¼ å›¾ç‰‡")
            logging.info(f"ğŸ“ å›¾ç‰‡ä¿å­˜åœ¨: {self.images_dir}")
            logging.info("ğŸ”— ç°åœ¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®ï¼š")
            logging.info("   - API: http://localhost:3000/api/debug/catalogue-images")
            logging.info("   - ç›´æ¥è®¿é—®: http://localhost:3000/catalogue_images/coles/")
            logging.info("ğŸ‰" + "=" * 50)
            return True
                
        except Exception as e:
            logging.error(f"âŒ çˆ¬è™«æ‰§è¡Œå¤±è´¥: {e}")
            return False
            
        finally:
            self.close_driver()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›’ Colesè‡ªåŠ¨åŒ–çˆ¬è™«å¯åŠ¨ä¸­...")
    
    scraper = ColesScraper()
    success = scraper.run_scraper()
    
    if success:
        print("\n" + "ğŸ‰" * 20)
        print("âœ… Colesçˆ¬è™«æ‰§è¡ŒæˆåŠŸï¼")
        print("ğŸ¯ ç°åœ¨å¯ä»¥æµ‹è¯•APIäº†")
        print("ğŸ‰" * 20)
    else:
        print("\nâŒ Colesçˆ¬è™«æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()